# 3. Foundations of Public Opinion on the Affordable Care Act

## Abstract

Despite some preliminary research on the nature of public opinion regarding the Patient Protection and Affordable Care Act of 2010 (ACA), there is still work to be done in understanding how people form and change their opinions of this important policy, as well as how analysts should interpret those opinions. This paper reports results of a survey experiment designed to give insight into the underpinnings of public opinion on the ACA. Respondents were asked a series of questions about the ACA, with the order of some questions varied randomly to create a priming effect. Based on this study, I find that both favorability toward the ACA and correlates of ACA opinion vary according to the kind of information with which a respondent is primed. Priming different policies elicits different patterns of change in opinion distributions. It seems that not only is public opinion on the ACA responsive to the kinds of information presented to respondents, but the ways in which opinions are formed may also be malleable. Future work could explore these ideas further, but this survey experiment represents progress in our understanding of public opinion on the ACA.

## Introduction

While the Patient Protection and Affordable Care Act (ACA) was passed over five years ago, the political debate over the health reform law has not yet ended. There have been numerous court cases about the law and specific parts thereof. The House of Representatives has voted numerous times to repeal the law outright. Many states have refused to expand Medicaid and have opted to use the Federal insurance exchange rather than setting up their own state exchanges. Public opinion on the ACA is still mixed [@DiJulio2015], and as the 2016 presidential election field takes shape, the ACA has already proven likely to be an issue in the election. In their analysis of the ACA’s shaky political foundation, Oberlander and Weaver conclude "the fight over Obamacare is not over" [@Oberlander2015].

One key player in the fight so far has been public opinion. Public opinion affects health policy through elections and other influences on elected officials [@Jacobs2000; @Jacobs1993; @Skocpol1994; @Skocpol1996], who will ultimately decide the law’s fate. To understand how ongoing political struggles might affect the ACA, we need to understand public opinion and how it might change (or not). In this study, I present findings from a survey experiment intended to examine the foundations of opinion on the ACA and suggest future pathways for investigation of this important topic. The results suggest that both opinions of the law and the way those opinions are formed can change depending on what information is in the person’s mind at the time.

## Background

Previous research has advanced our understanding of public opinion on health reform in a few key ways. Partisanship is highly correlated with peoples’ opinions of the law [@DiJulio2015]. Polling has also shown that although slim majorities have generally opposed the ACA as a whole, voters overwhelmingly favor some parts of the law [@Brodie2010]. However, there is a sizable portion of voters who do not express any opinion on the ACA [@DiJulio2015], and research shows these people are systematically different from those who do express opinions in terms of demographic and socioeconomic characteristics [@Berinsky2011]. These findings suggest some general contours for opinion on health reform, but our knowledge about how the landscape might shift is less certain. Understanding the dynamics of public opinion is important in predicting how the debate will play out.

In examining ACA opinion dynamics, research has yielded a couple of important clues. First, favorability toward specific provisions in the ACA can be manipulated depending on how the issue is framed. Reported favorability toward the individual mandate is higher when the survey question mentions subsidies for low-income families to purchase insurance, but lower when the question brings up the fact that some people choose not to have health insurance relative to questions that do not mention these specific provisions [@Grande2011]. However, while framing can affect the level of support for specific policy proposals, we do not know how opinions of specific provisions might affect opinion of a reform package as a whole.

Second, increased knowledge about the ACA is positively correlated with opinions of the law [@Gross2012]. As knowledge of specific parts of the ACA increases, reported favorability for the entire law increases. However, we cannot assume this is a causal effect. It could be that those who favor the ACA seek out more information about the law because they favor it. Another possibility is that a third factor (partisanship is a plausible candidate), preceding both ACA knowledge and ACA opinion, is causing both, rendering the correlation between knowledge and opinion spurious. Still, we do see a correlation between knowledge and opinion. This is an important lead calling for further investigation.

Two political science theories related to public opinion will be useful in directing research on ACA opinion dynamics. First is the memory-based model of the survey response [@Zaller1992a]. According to this model, a person asked to respond to a survey question first retrieves a few relevant pieces of information. This is not an exhaustive (or exhausting) search of one’s entire memory, but rather a nonrandom sample of considerations conveniently at the "top of the head." The retrieved considerations are processed and mapped onto possible answers to the question. Thus, reported attitudes may change significantly, depending on what relevant information has been on a respondent’s mind recently. By this model, we cannot expect opinions of the ACA to be stable within individuals over time (though stability will vary based on political sophistication), nor can we expect people to always base their opinions on thorough analysis of what the ACA says or does [@Zaller1992a]. However, we can expect peoples’ opinions to be susceptible to priming of different kinds of information. Changing the items at the top of the head may change both the expressed opinion and the way that opinion is formed.

For the ACA in particular, well-known parts of the law like the individual mandate or the contraception coverage requirement will probably be more salient than lesser-known provisions, like incentives for Accountable Care Organizations (ACOs). This is simply because average respondents are more likely to have heard about particular pieces of the law that have been in the news. ACOs have not stirred much controversy outside of health policy circles, but coverage of contraceptives was at least for a time a major topic of public debate in the wake of the Supreme Court’s *Hobby Lobby* ruling. The memory-based respondent does not need to fully understand the law’s coverage requirements to connect the general notion of contraception coverage to the ACA; the media made it clear to those who listened that the two go together. Because of public discourse on some of these technical aspects of health reform, these details of the law will become associated with the law in people’s minds. Those associations may then be sampled when a pollster asks for an opinion. What all this suggests is that pieces of the law which are salient at the time of response will factor more prominently in the respondent’s construction of the response.

The second political science theory that might be useful for understanding ACA opinion dynamics is the notion of "hard" vs. "easy" issues [@Carmines1980]. Hard issues are those which sophisticated voters are able to judge based on understanding technical aspects of the issue. Easy issues, on the other hand, are judged through "gut reactions." These issues are symbolic, focused on ends rather than means, and prominent on the political agenda for an extended period of time. The ACA, considered solely as a complex health reform bill with its many moving parts, fits the definition of a hard issue [@Berinsky2011]. However, the debate over the law fits the criteria of an easy issue. It is loaded with political symbolism, focused on fundamental ends (getting the government in or out of health care), and has been a prominent agenda item for over five years. The Obama-era debate over health reform might be best classified as a hybrid of the two issue types [@Johnston2015]. If that is the case, perhaps people can be influenced to think about the ACA in "hard" or "easy" terms.

Combining these two models and their implications, we can derive two hypotheses to be tested in this study. First, we might expect that if provisions within the ACA are salient at the time of response, then overall opinions of the ACA will be different than they would be if those provisions were not salient. Put another way, if a respondent is primed to think about a specific provision, their reported favorability of the ACA would differ from the favorability reported by an otherwise similar person not primed to think about the provision.

Second, we might expect the way in which responses to the ACA favorability question are formed to vary according to what information is salient at the time of response. If a specific provision is salient (perhaps because of priming) in a respondent’s mind at the time ACA favorability is reported, then the respondent’s opinion of the ACA will be more strongly affected by his/ her opinion of the salient provision. If no specific provisions are made salient (primed), then other factors will be more important in forming the opinion. This hypothesis gets at a possible causal mechanism underlying the changes in expressed opinions described in the first hypothesis.

## The Study

To test the hypotheses raised above, I conducted a survey experiment [@Mutz2011] in November 2014 on Amazon’s Mechanical Turk (MTurk) service. In the experimental portion of the survey, random assignment was used to sort respondents into one of four experimental conditions, outlined in Figure 1. In two of the experimental groups, respondents were first asked to respond to two questions about their opinion of the ACA in general. These two groups then responded to questions about specific pieces of the law. One group answered questions about the individual mandate, while the other was asked about the provision requiring that adults under age 26 be allowed to remain on their parents’ insurance plans. I refer to both of these groups as the unprimed or control groups. For the other two groups, which I refer to as the primed or treatment groups, the order of the two question blocks was reversed, so the provision-specific questions came first and the general ACA questions appeared afterward. The question wordings and their order within the blocks remained constant. Only the order of the blocks and the specific provision referred to in the questions was changed.

Table 1: Descriptive Statistics

**\[Figure 1 about here\]**

By manipulating the order of the questions, respondents in different groups had different considerations "at the tops of their heads" when responding to the general ACA questions. The primed groups had been primed to think about the specific provisions they were asked about immediately prior to giving their opinions of the law as a whole.

In the results presented below, I set up comparisons based on the specific provisions about which each group was asked. For example, the unprimed group asked about the individual mandate (group 1 in Figure 1) is used as a control group, to be compared to the group first primed with questions about the individual mandate (group 2). Similar comparisons are made for the other two groups, with the primed group serving as a treatment group and the unprimed group serving as control.

In the initial wave of the experiment (Nov. 22 and 24, 2014), 506 responses were collected. Each respondent was paid \$0.40 for completing the survey (repeat responses were not allowed). This wave included my survey experiment and two other vignette experiments conducted by two other researchers about racial group identity and terrorist recruiting messages. More information about the other two studies is available from the author upon request. My study appeared first, followed by the other two, with demographic questions at the end. After completing the experimental portion of the survey, respondents reported their level of approval of President Obama, their partisanship and political ideology, their racial identities and religious affiliation, their level of attentiveness to news and current events, their insurance status, and their income level. Specific question wording for my experimental questions and for demographic questions is given in Appendix C.

Upon preliminary examination of the data from the initial wave, it was discovered that the code for my portion of the survey had failed to randomize the order of the general ACA and specific policy questions. This meant I only had data for the two unprimed groups, my "control" groups. In order to collect data for the other two groups, I was able to put my survey experiment (along with the same demographic questions, but excluding the other two experiments) back into the field on MTurk on Nov. 25, 2014, with a compensation rate of \$0.12 per respondent.[^1] Those who had taken the survey previously were barred from participating again. This second wave yielded 396 additional responses. I randomized the treatment group assignments for this second wave in such a way that all four groups were represented, but with twice as many respondents assigned to the two groups that had been omitted in the first wave (the primed groups).

Collecting data on all four groups in the second wave allowed me to assess whether respondents to the two waves were different based on observed characteristics. I checked to ensure that there were no significant differences in the types of respondents to the two waves. Each wave had a different estimated completion time and a different level of compensation, in addition to being fielded on different days. General results of these balance checks are reported in the tables in Appendix A, along with final sample sizes within each treatment group. Thus, the analyses in the main body of this paper combine data from both waves of the survey, with treatment presumed to be given at random. Results do not change significantly when respondents from the first wave are omitted.

The use of MTurk as a survey platform has many limitations. As an opt-in survey conducted over the Internet, there is no way of randomly selecting respondents, nor is there any way to calculate response rates, refusal rates, margins of sampling error, or any of the usual survey metrics. The respondents to my survey do not resemble the demographic or political profiles of the US population, as can be expected from a subject pool such as MTurk. However, experimental results using MTurk have proven comparable to those obtained from other subject pools [@Mullinix2015]. Thus, for examining the way opinion distributions change in response to certain factors, MTurk may be an acceptable platform. As it is not my intent to estimate population parameters, but rather to gauge the effects of an experimental manipulation, data collected on MTurk is suitable for this study.

## Sample Demographics and Descriptive Statistics

I asked respondents for their level of approval/ disapproval of President Obama, party identification (using the standard ANES question), ideology (liberal to conservative, 7-point scale with ANES wording but no branching), racial and religious identification, level of attentiveness to news, health insurance status, and income. As mentioned above, MTurk does not provide a good platform for representative survey results, and my sample is skewed on all observable characteristics in the ways we would expect of MTurk respondents. They are more liberal and Democratic, more likely to be uninsured, and have lower incomes than we would expect from a general US adult sample. Over half of the sample reported having no religious affiliation, and only about 34 percent identified as Christian. Table 1 gives the distributions of these political and demographic characteristics for the entire sample, as well as distributions of the opinion variables used in my study.

![Figure 1: Survey Experiment Design](C:\Users\Robbie\Documents\dissertation\Analysis\Figs\fig3-1.png)

The table indicates very little missing data. Only five respondents skipped any questions, and these five account for all missingness in the data. The five incomplete responses are excluded only from models that include variables for which there is missing data.

Based on Table 1, we see that over half of the respondents in the sample favored the ACA, another way in which the sample departs from the U.S. adult population (which has less favorable attitudes toward the ACA). We also see that most people knew that the specific provision they were asked about was in the final version of the law, and over half for each provision thought the provision would affect them or someone close to them. Attitudes toward the individual mandate were somewhat mixed, though as predicted more people opposed it than supported it. The young adult coverage provision had very high favorability in this sample, perhaps a result of the generally younger profile of MTurk users, though I do not have the data to support that hypothesis for this sample. The skewed distribution of opinion on the YA provisions may affect the results of some of my hypothesis tests, which is worth noting here as a potential limitation.

## Results

If priming different considerations had any effect on opinions, as expected in the first hypothesis, we would expect to see differences in ACA approval levels between the treatment and control groups. Accordingly, I use basic t-tests to determine whether there were significant differences in the mean levels of ACA approval by experimental group. As displayed in Figure 2, the two unprimed groups hold similar distributions of opinions on the ACA, and changes occur in the expected directions for the primed groups. Those asked first about the individual mandate have somewhat less favorable opinions of the ACA. The difference is close to significance (t = 1.79, p =0.074), though it does not clear the 0.05 two-tailed threshold and becomes even less statistically significant in alternative specifications of the test (not shown). The effect for the young adult coverage group is stronger (t = -3.62, p &lt; 0.001), achieving significance well beyond the conventional level, with the substantive effect of increasing favorability by almost three quarters of a scale point on the seven-point favorability scale.[^2]

![Figure 2: ACA Favorability by Experimental Group](C:\Users\Robbie\Documents\dissertation\Analysis\Figs\fig3-2.png)

Note: Error bars represent 95% confidence intervals based on unpooled standard errors. The y-axis variable ranges from 1-7, and is treated as continuous in this analysis. Results do not change significantly when the dependent variable is changed to a dummy representing presence of any favorable feeling toward ACA. The numbers underlying this figure appear in the supplementary online materials, Appendix B, Table B-1.

The decrease in favorability for the group primed with the individual mandate questions shown in Figure 2 is commensurate with the mixed feelings toward the individual mandate expressed in the survey. The young adult coverage provision, by contrast, had much clearer positive effects on the other primed group’s perceptions of the ACA. One possible reason for the less significant effect of the individual mandate is the nature of the prime. As @Grande2011 found in their study, feelings on the individual mandate were relatively more positive when using a description of the policy similar to the one I employed.

We might expect that priming the individual mandate will only negatively affect overall ACA opinions of those who oppose the individual mandate. Thus, another way to analyze this data is to break the groups down further into those who favored and did not favor each provision. Figure 3 shows this subgroup analysis. Among those who do not favor the individual mandate, opinions of the ACA are significantly less favorable when primed (t = -3.47, p < 0.001). For the group that favored the individual mandate, the prime did not change opinions (t = -0.812, p = 0.418).

![Figure 3: ACA Favorability by Experimental Group and Provision Support](C:\Users\Robbie\Documents\dissertation\Analysis\Figs\fig3-3.png)

Note: Error bars represent 95% confidence intervals based on unpooled standard errors. The y-axis variable ranges from 1-7, and is treated as continuous in this analysis. Results do not change significantly when the dependent variable is changed to a dummy representing presence of any favorable feeling toward ACA. The numbers underlying this figure appear in the supplementary online materials, Appendix B, Table B-1.

The same is not true of those in the young adult coverage conditions. No matter how individuals in this group felt about the specific provision, priming the provision increased favorability toward the ACA in general. The "do not favor" segment of this group is somewhat small (only 21 people in the primed portion had less than favorable opinions of this provision), limiting the precision of the estimates for this group. Still, we see evidence here that priming different pieces of the law had different effects on people’s opinions. For the individual mandate, the effect depends on how the person feels about the individual mandate. For the young adult coverage provisions, the effect of the prime is not dependent on provision-specific opinions.

The main findings in Figures 2 and 3 hold for various subsets of the sample and various specifications of the test. Using a dummy variable as the dependent variable rather than the continuous seven-point scale yields qualitatively similar results (the individual mandate prime still has a non-significant negative effect). Effects are the similar when the samples are split into those who knew the provisions made it into the final version of the law and those who did not, though it is interesting to note that the effects are stronger for those who did not know the young adult provision was in the law. The individual mandate prime was also stronger for those who did not know the individual mandate was in the ACA, but the prime was not significant for either group.

The results presented above might be biased if the question order affected respondents’ opinions of the specific ACA provisions. However, in t-tests similar to the ones reported above, but with provision-specific opinions as the dependent variables, asking the overall ACA questions first creates no significant differences in opinions on either provision. For the individual mandate groups, t = 0.052 (p = 0.96), and for the young adult coverage groups, t = -1.19 (p = 0.23). For the young adult group in particular, this is remarkable given the potential for cognitive dissonance to decrease peoples’ willingness to favor any part of a law they just said they opposed on the whole. That is what happened if we only look at the point estimates, but again that effect is not significant. Apparently, people are not as willing to judge the ACA’s parts based on the whole as they are to judge the whole based on which parts are salient at the time of response.

We might also expect the null findings just described because of the way the experiment was set up. In the initial instructions, respondents are reminded that a "health reform bill known as the Affordable Care Act (ACA) or Obamacare was signed into law in 2010." The provision questions also referred back to the ACA, regardless of when they appeared in the survey. This means every respondent was "primed" to think about the ACA, with the only difference being that some of the respondents had answered two questions about the ACA before giving their opinions on specific provisions. Empirically, this difference in the level of the ACA prime does not seem to have had any effect, as the t-tests above show.

We might also expect the null findings just described because of the way the experiment was set up. In the initial instructions, respondents are reminded that a "health reform bill known as the Affordable Care Act (ACA) or Obamacare was signed into law in 2010." The provision questions also referred back to the ACA, regardless of when they appeared in the survey. This means every respondent was "primed" to think about the ACA, with the only difference being that some of the respondents had answered two questions about the ACA before giving their opinions on specific provisions. Empirically, this difference in the level of the ACA prime does not seem to have had any effect, as the t-tests above show. Thus, it is reasonable to assume that the question order manipulation is not affecting opinions of the specific provisions. "Reverse priming" does not seem to be an issue for this study.

As expected from our first hypothesized, ACA opinions appear to be subject to priming effects. Are the ways in which opinions are formed also dependent on priming? If so, we would expect to see differences between treatment and control groups in terms of the predictors of ACA approval, as in our second hypothesis. To test this hypothesis, I estimated OLS regression models for the four groups separately, with the final models using level of ACA approval as the dependent variable and opinions of specific provisions, presidential approval, and partisanship as predictors. Other covariates like ideology, income, race, religion, and insurance status did not affect the models significantly when included, so I exclude those from the final models reported below. I then conducted t-tests to determine whether the effects of individual variables differed between the control groups and their respective treatment groups. F-tests were also used to test whether the overall models were jointly different from each other. These tests of differences in effects indicate whether the experimental manipulation had any effect on the determinants of ACA opinion.

![Figure 4: Models of ACA Approval by Treatment Group](C:\Users\Robbie\Documents\dissertation\Analysis\Figs\fig3-4.png)

Note: Coefficient values measured on the x-axes represent the effects of each variable on overall ACA opinion (seven-point scale). The opinion and presidential approval control variables are also continuous seven-point scales. The partisanship variables are all dummies, with independents excluded as the baseline categories. No other variables are included in the model. The constants for the models are not reported. Sample sizes for the models were 124 for primed individual mandate model, 321 for the unprimed individual mandate model, 129 for the primed young adult coverage model, and 326 for the corresponding unprimed model. See Appendix A for an explanation of the disparities in group sample sizes. The adjusted R^2^’s for the models range from 0.46 to 0.76. Full models are shown in tabular form in the supplementary online materials, Appendix B, tables B-2 and B-3.

Figure 4 plots the coefficients from the four models, with 95% confidence intervals. Tables containing the full model information are found in Appendix B. The models show that opinions of specific provisions significantly affect overall opinions of the ACA in all treatment groups. As support for either of the two provisions increases, support for the ACA overall also increases. However, in the individual mandate models, the effect of provision-specific opinions is somewhat stronger for the primed group than the unprimed group, with a difference of about 0.13 on the seven-point scale. What this means is that the prime seems to have made the effect of individual mandate opinions on ACA opinions stronger relative to the unprimed group. This finding of a difference in the two coefficients is not quite statistically significant (t = 1.73, p = 0.085), but a significant finding of this type would be consistent with my predictions. The 0.13 increase in effect size is extremely robust across different specifications of the model, leading me to suspect the null finding is more of a power issue than an actual lack of a priming effect.[^3] There is no consistent or significant difference in the primed and unprimed coefficients for the young adult coverage group models.

I also ran F-tests for the equality of the models within each provision group across priming conditions. It could be that as the policy-specific opinions become stronger predictors, these effects might override other factors like partisanship or one’s opinion of President Obama. The differences in the individual mandate models seem to support this hypothesis. Specifically, whether or not the respondent was a Republican mattered a great deal in the unprimed individual mandate model, but very little in the corresponding primed model. This, along with the finding presented above, indicates a change in the predictors of ACA opinion as a result of the prime. The F-test indicates a significant difference in the two models overall (F = 4.72, p = 0.001). Whether one is primed to think about the individual mandate appears to affect how one forms an opinion of the ACA. The same cannot be said of the young adult coverage models (F = 0.72, p = 0.58). The similarity of the young adult models may be a result of the low variance in opinions of the young adult coverage provision. Most respondents (almost 82 percent) liked this provision at least somewhat, and only eight percent had even a slightly unfavorable view of this provision. Nevertheless, the fact that partisanship is not a significant predictor of ACA opinions when a specific provision (the individual mandate) is primed is quite remarkable, given the explanatory power of partisanship in both of my unprimed models and in many other political science studies.

For the models and findings presented above, reverse causality becomes an issue. It may be the case that ACA opinions are also causing changes in provision-specific opinions, depending on which was asked about first. Models in which the provision opinions are the dependent variables and overall ACA opinions are controlled indicate that ACA opinions do indeed have significant effects on the provision-specific opinions. However, there are no significant changes in the effects of ACA opinions based on priming. The model coefficients, tested jointly as above, are also not significantly different. The threat of endogeneity is still present, and future work may be needed to get unbiased estimates of the conclusions I make here. Still, there is tentative support for my hypotheses, and reverse causality does not appear to directly explain those results.

## Discussion

This study has explored the nature of public opinion on the ACA, specifically investigating how two provisions in the law affect overall opinions. One policy, the young adult coverage provision, was found to be a powerful prime. When respondents answered questions about this provision first, their opinions of the ACA were more favorable than those of the unprimed group. While priming the individual mandate did not affect opinions overall (though it did for the subset who opposed the individual mandate), priming this more controversial provision did seem to change the way people formed their opinions of the ACA. The individual mandate prime made respondents’ opinions of the provision even more salient and their partisanship less salient in expressing their favorability toward the law as a whole.

In thinking about how opinions of specific provisions within the ACA affect opinions of the law overall, my results suggest it is important to think about both the central tendencies and variances of those opinions. Priming a widely supported provision may change the way people view the law, but not the way they form their opinions of the law. On the other hand, priming a more controversial provision may actually change how people form opinions of the ACA. There is certainly room for future research along these lines. Specifically, more provisions could be tested to see if these results can be generalized beyond the individual mandate and young adult coverage provisions. Resource constraints prevented me from testing more provisions in this study.

As mentioned above, public opinion has already affected the implementation of health reform, and will continue to do so. The results of this study offer important insights for the ongoing political debate over the ACA and US health reform in general. First, the findings presented above suggest that public opinion is malleable and depends on what people are thinking about when their opinions are recorded. Given the symbolic, "soft-issue" way in which the ACA is discussed in popular discourse, people are probably viewing the ACA in those terms rather than on technical, "hard-issue" grounds. Thus, polls asking about the ACA in general may not even be useful barometers of public opinion on the actual policy. Instead, such questions are likely tapping the balance of opinion on symbolism and rhetoric surrounding the ACA at the time. If policymakers and analysts want to understand what the public wants policy to do, then perhaps asking about specific provisions would be more useful.

Another implication is that the mix of considerations and characteristics factoring into peoples’ opinions of complex policy packages can be changed. If people are asked to think about the specific provisions of a policy like the ACA, they will evaluate the whole based on its parts. However, they are not likely to do so when not asked to. Rather, their opinions will be based on other factors, like partisanship. Politicians may even try to manipulate the considerations people use in evaluating the ACA through the use of "crafted talk," essentially an attempt at priming opinion through use of the media [@Jacobs2000]. For analysts and policymakers, this is important to understand because it affects the way we interpret measurements of public opinion. Is the ACA being judged on technical, hard-issue terms, or by symbolic, soft-issue criteria? The answer is probably dependent on many specific factors, most of which are not explored in this study, but the results presented above do suggest the importance of answering this question.

Future research should examine the dynamics of opinion on the ACA further. My results suggest that different primes may have different effects. This study only employs primes of two specific provisions in the ACA, but there are certainly many others. As political rhetoric continues, scholars should examine the ways in which different messages about health reform affect public opinion.

## References

[^1]: The lower compensation is a result of not having the other two experiments in this wave, resulting in a much shorter questionnaire.

[^2]: I treat the seven-point scale of ACA favorability as a continuous variable in this analysis, but results do not change significantly when I specify the dependent variable as a dummy indicating any favorable feelings toward the ACA (with neutral and any unfavorable in the 0 category)

[^3]: Indeed, a rough power analysis indicates I would need to double the number of observations (from 445 to about 897) in the joint model being tested to detect this effect with even a 0.7 power coefficient.
