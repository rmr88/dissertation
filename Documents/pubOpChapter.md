# 3. Interpetive Feedback Effects and Public Opinion on the Affordable Care Act: A Survey Experiment

While the Patient Protection and Affordable Care Act (ACA) was passed over six years ago, the political debate over the health reform law has not yet ended. There have been numerous court cases regarding the law and specific parts thereof, with the court declaring a key piece of the law, the Medicaid expansion requirement, unconstitutional and leaving the decision up to the states. Many states have refused to expand Medicaid, and have also opted to use the Federal insurance exchange rather than setting up their own state exchanges as the law's architects initially envisioned. The House of Representatives has voted dozens of times to repeal the ACA. One recent attempt actually made it through the Senate (on reconciliation, which waives the Senate's supermajority requirements for cloture) and to the President's desk, where it was promptly vetoed. With Republicans having held both chambers in Congress and winning the presidency in the 2016 elections, talk of repeal has become even more serious. In their analysis of the ACA's shaky political foundation, Oberlander and Weaver conclude "the fight over Obamacare is not over" [@Oberlander2015].

Public opinion on the ACA is still mixed, with small but persistent pluralities in opposition [@DiJulio2015; see also @Jacobs2016]. This matters for the law's future. Public opinion affects health policy through elections and other influences on elected officials [@Jacobs2000; @Jacobs1993; @Skocpol1994; @Skocpol1996], who will ultimately decide the law's fate. For example, the actions of some states to block Medicaid expansion and even to close down otherwise successful state health insurance exchanges, as Kentucky is in the process of doing, are a result of continued public opposition and elected officials who represent that opposition. Thus, if the law itself is designed in a way that elicits a certain public response, then policy design (or the conversation surrounding the policy as designed) becomes a relevant factor to consider in assessing a policy's political future [@Pierson1993; @Pierson2000; @Campbell2012; @Oberlander2015].

One of the most important factors to examine is the effect of the law itself, as it is both implemented and interpreted, on public attitudes. It is possible the law was not written in such a way that will build support on its own, and that it will instead collapse, be repealed, or be watered down to the point of insignificance. Whether this will occur depends in part on how the public views the ACA in light of what the law actually does. In this study, I present findings from a survey experiment designed to examine how specific ACA provisions might affect support for the ACA overall and thereby affect public opinion.

## 3.1 Background

Previous research on public opinion on health reform yields some key insights regarding the politics of the ACA. Support for the ACA or health reform in general is correlated with favorability toward specific provisions in the law [@Brodie2010; @Grande2011], increased knowledge of the law [@Gross2012], partisanship and self-interest [@Gross2012; @Henderson2011; @DiJulio2015], racial attitudes [@Henderson2011; @Tesler2012], demographic and socioeconomic characteristics [@Berinsky2011], and beliefs about who deserves government assistance [@Gollust2011]. Using a panel survey design, @Jacobs2016 analyzed within-person trends in ACA opinion over time, as well as the effects of partisanship, perception of direct benefits from health reform, and other factors on those overall opinions. They find that opinion on the law has remained divided, with personal opinions remaining largely entrenched over time, but with significant decreases in support for repealing the ACA. While they conclude that outright repeal of the ACA grows less likely with the passage of time, there is also no evidence that political support for the law will increase any time soon in the manner that reformers initially hoped.

Most of the studies mentioned above examine the ways individuals with different characteeristics might view the ACA. What I test in this study is different. I am seeking to show how the design of the ACA itself, as well as the conversation surrounding it, affects opinions toward the ACA. This is not to say that individual-level characteristics do not matter. However, it will be useful in future policy making endeavors to know more about how the design of the ACA affected its reception.

One way to test whether policy design affects public opinion is to manipulate a group's understanding of a policy and see how that group's opinion of the policy differs from a similar group with a different interpretation. This study uses a survey experiment to do just that, by examining whether priming different aspects of a reform package changes overall opinions. This procedure mirrors survey experiments reported in the survey methodology literature, such as a classic experiment reported by @Schuman1981 in which respondents were much more likely to favor allowing communist reporters into the US when they were first asked whether the Soviet Union should admit American reporters. This and other similarly designed experiments have been shown to change the "weights respondents give to the factors relevant to answering a question" [@Krosnick2010, 293]. Furthermore, asking specific questions about a topic before asking more general questions can affect the context in which answers to the more general questions are generated [@Krosnick2010].

Using this survey experiment design, I test two hypotheses. First, we might expect that if ACA provisions are primed before overall opinion of the ACA is reported, those overall opinions will be different than if the specific provisions were not salient. Put another way, if respondents are primed to think about a specific provision, their average reported favorability of the ACA should differ from the favorability reported by otherwise similar respondents not primed to think about the provision.

Second, we might expect the way in which responses to the ACA favorability question are formed to vary according to what information is salient at the time of response. If a specific provision is salient (because of priming) in a respondent's mind at the time ACA favorability is reported, then the respondent's opinion of the ACA will be more strongly affected by his/ her opinion of the salient provision. Conversely, if no specific provisions are primed, then other factors will be more important in forming the opinion.

Not all design aspects of a law will necessarily affect opinions in the same way, or at all, so we need to flesh out these predictions further by considering what effects particular kinds of policies/ design features might have on opinion. To that end, I will distinguish between "policy pork" provisions and potential wedge provisions.

I define policy pork as a provision that is expected to be almost universally favored and can feature prominently into political messaging targeted at voters or a particular group of voters. This is similar to the pork provisions analyzed by congressional scholars in the context of policy making and legislative parties [@Evans2004; @Smith2007; @Binder2015]. Based on that research, pork provisions confer benefits on specific voters or groups of voters in order to entice their representative to support the overall bill. The pork ensures that, even if the member of Congress might otherwise vote against a bill on policy grounds, he or she will see a political benefit of voting in favor. Funding for a specific school, a new Federal building, or a new highway project in the representative's district are examples of pork that have been added to unrelated bills to entice specific legislators to vote in favor.

Policy pork, in my usage, is similar to the standard definition of pork in that it may be unrelated to or severable from the broader policy, included more as a way to garner political support rather than to achieve the policy goals of the overall proposal. I view policy pork as a unique, unexplored kind of pork. @Evans2004 notes that studying pork distributed in non-geographic ways is difficult, and we could also add that pork that does not invlove appropriations could be even more difficult to track. Policy pork is included in a legislative package not because it is itself an end goal of the legislation, but rather because it serves the same purpose as pork: generating political support for the bill.

One piece of policy pork in the ACA is the requirement that young adults be allowed to remain on their parents' insurance plans until age 26, which I will refer to as the dependent coverage provision for short. This provision is almost universally favored [@Brodie2010]. After passage, ACA proponents could point to this quick, easy benefit of the ACA and promise more good things to come if voters will just stick with this newfangled health law (while downplaying the costs that must also come eventually). It is important to keep in mind that this provision is not tied to the rest of the ACA in any logical or substantive way; it could have passed on its own, and was not necessary to the policy success of the ACA. It is not obvious that allowing dependents to remain on their parents' insurance until age 26 necessarily goes along with a mandate for most individuals to buy health insurance.[^1] The absence of a logical link between these elements means a rhetorical link must be made and maintained, for example by calling it part of "health reform." This is harder to do as the program progresses through implementation and more controversial elements enter the public conversation on the law. As a tool for managing how policy design affects opinion, policy pork only works to the extent that opposition is broken down preemptively through early, effective messaging on these provisions.

I will call the other type of design feature to be examined in this paper a potential wedge provision. I say "potential" because some outside effort is required to make these provisions politically potent. If those in favor of the policy control the discussion, perhaps through effective use of policy pork, the wedges will not be hammered down politically (though they might be felt in other ways). The individual mandate, the ACA's requirement that most individuals purchase health insurance or pay a fine, is an example of a potential wedge provision. This controversial provision has varying levels of support, depending on the way it was described in survey questions [@Grande2011], giving it the potential to enhance public divisions on the whole reform package.

Politicians try to include as few wedge provisions as possible in a new law in order to increase its chances of political success. They want to consolidate support, not divide it, and they want to keep political opponents from creating such divisions. However, depending on the constraints imposed on would be reformers [@Patashnik2013], some wedges may be unavoidable. The designers of the ACA decided early on that they would try to leave intact as much of the status quo as possible [@Oberlander2015]. This meant the ACA almost certainly had to include an individual mandate, despite the political difficulty of selling such a proposal to the public. Reformers' political strategy was to include enough policy pork in the bill to head off opposition before the potential wedge provisions were implemented. Opponents, given that they were unable to stop the policy from passing, hoped to use these wedge issues to prevent such a support coalition from fully forming. However, if their base of support crumbled early by general acceptance of the pork-filled law, the opposition's wedge tactic would lose its potency.

To tie these concepts back to the hypotheses for this study, we would expect the two kinds of design features to have different effects on opinion. If policy pork like the dependent coverage provision is primed, then opinions of the ACA should become more favorable. If a wedge provision like the individual mandate is primed, overall favorability will depend more on which side of the wedge people are on (i.e. whether they favor or oppose the mandate in particular). This adds some conditions to hypothesis 1. It also bolsters the conceptual argument in favor of hypothesis 2 in the case of wedge issues, because the wedge itself should become a more important predictor of overall opinions if people are first reminded of the wedge.

The hypotheses for this study can be summarized as follows:

1. If specific provisions of the ACA are primed before overall ACA opinion is reported, then overall favorability toward the ACA will be different than that reported by similar repsondents who are not primed.
	a. If a policy pork provision is primed, we would expect to see movement in favor of the ACA.
	b. If a wedge issue is primed, aggregate opinion may not move, but opinions of certain subgroups will move in opposite directions depending on opinions of the wedge itself.
2. The correlates of overall ACA opinion will be different if specific provisions are primed, relative to the correlates for similar unprimed respondents.
	a. When a wedge issue is primed, opinions about the wedge will become more significantly correlated with overall opinions of the law.
	b. Priming a policy pork may also change correlates of opinion, but the prediction is admittedly weaker for this condition.

By testing these hypotheses, we can assess whether certain design aspects of the law affect the public's interpretation of and favorability toward the ACA as a whole. Note this is not a test of favorability towards the provisions themselves, nor is it an estimate of the population parameter for ACA favorability. The hypotheses deal with changes in average opinion, not estimates of average opinion itself. Data in support of these hypotheses would, however, increase confidence that priming policy provisions (thereby making respondents interpret the law differently) causes aggregate opinion change.

## 3.3 The Study

To test the hypotheses raised above, I conducted a survey experiment [@Mutz2011] in November 2014 on Amazon's Mechanical Turk (MTurk) service. MTurk respondents have the opportunity to complete a wide range of simple tasks, such as tagging images, coding expense reports, and taking surveys, in return for small financial rewards. Respondents opt in to each task, using MTurk's user interface that presents a list of available tasks and can be filtered or sorted by task metadata such as keywords, date, and payment amount. The exact topic of my survey was concealed until after respondents had opted in. Respondents knew they would take a survey, but not that it would deal specifically with the ACA. Implications of the choice of this subject pool are discussed later.

In the experimental portion of the survey, random assignment was used to sort respondents into one of four experimental conditions, outlined in Figure 3-1. In two of the experimental groups, respondents were first asked to respond to two questions about their opinion of the ACA in general. These two groups then responded to questions about specific pieces of the law. One group answered questions about the individual mandate (the requirement that most individuals purchase health insurance or pay a fine), while the other was asked about the provision requiring that adults under age 26 be allowed to remain on their parents' insurance plans. I refer to both of these groups as the unprimed or control groups. For the other two groups, which I refer to as the primed or treatment groups, the order of the two question blocks was reversed, so the provision-specific questions came first and the general ACA questions appeared afterward. The question wordings and their order within the blocks remained constant. Only the order of the blocks and the specific provision referred to in the questions was changed.

![Figure 3-1: Survey Experiment Design](C:\Users\Robbie\Documents\dissertation\Analysis\Figs\fig3-1.png)

By manipulating the order of the questions, respondents in different groups had different considerations "at the tops of their heads" when responding to the general ACA questions. The primed groups had been primed to think about the specific provisions they were asked about immediately prior to giving their opinions of the law as a whole.

In the initial wave of the experiment (Nov. 22 and 24, 2014), 506 responses were collected. Each respondent was paid \$0.40 for completing the survey (repeat responses were not allowed). This wave included my survey experiment and two separate vignette experiments conducted by two other researchers about racial group identity and terrorist recruiting messages. More information about the other two studies is available from the author upon request. My study appeared first, followed by the other two, with demographic questions at the end. After completing the experimental portion of the survey, respondents reported their level of approval of President Obama, their partisanship and political ideology, their racial identities and religious affiliation, their level of attentiveness to news and current events, their insurance status, and their income level. Specific question wording for my experimental questions and for demographic questions is given in Appendix 3C.

Upon preliminary examination of the data from the initial wave, it was discovered that the code for my portion of the survey had failed to randomize the order of the general ACA and specific policy questions. This meant I only had data for the two unprimed groups, my "control" groups. In order to collect data for the other two groups, I was able to put my survey experiment (along with the same demographic questions, but excluding the other two experiments) back into the field on MTurk on Nov. 25, 2014, with a compensation rate of \$0.12 per respondent.[^2] Those who had taken the survey previously were barred from participating again. This second wave yielded 396 additional responses. I randomized the treatment group assignments for this second wave in such a way that all four groups were represented, but with twice as many respondents assigned to the two groups that had been omitted in the first wave (the primed groups).

Collecting data on all four groups in the second wave allowed me to assess whether respondents to the two waves were different based on observed characteristics. I checked to ensure that there were no significant differences in the types of respondents to the two waves. Each wave had a different estimated completion time and a different level of compensation, in addition to being fielded on different days. However, there is no indication that responses were affected by these differences. Balance checks revealed that on all 16 items relevant to my survey (including both demographic and ACA-related items), only ideology differs significantly across waves, and that difference only appears for one specification of the variable. I control for ideology in my final models reported below. Specific results of the balance checks are reported in tables A3A-2 and A3A-3 (Appendix 3A), along with final sample sizes within each treatment group. The analyses in the main body of this paper combine data from both waves of the survey, with treatment presumed to be given at random. Results do not change significantly when respondents from the first wave are omitted.

### 3.3.1 Sample Demographics and Descriptive Statistics

The use of MTurk as a survey platform has some limitations. As an opt-in survey conducted over the Internet, there is no way to randomly select respondents, nor is there any way to calculate response rates, refusal rates, margins of sampling error, or any of the usual survey metrics. The respondents to my survey do not resemble the demographic or political profiles of the US population, as can be expected from a subject pool such as MTurk. However, experimental results using MTurk have proven comparable to those obtained from other convenient subject pools often used in experiments [see @Mullinix2015]. Thus, for an experimental design, MTurk is an acceptable platform. For the hypotheses I am trying to test, internal validity is more important than external validity. I will report below how the respondents to my survey are different from the population, but I see no reason to expect that my results will differ qualitatively if applied to the general population. As it is not my intent to estimate population parameters, but rather to gauge the effectiveness of an experimental manipulation, data collected on MTurk is suitable for this study.

I asked respondents for their level of approval/ disapproval of President Obama, party identification (using the standard ANES question), ideology (liberal to conservative, 7-point scale with ANES wording but no branching), racial and religious identification, level of attentiveness to news, health insurance status, and income. As mentioned above, MTurk does not provide a good platform for representative survey results, and my sample is skewed on all observable characteristics in the ways we would expect of MTurk respondents. They are more liberal and Democratic, more likely to be uninsured, and have lower incomes than we would expect from a general US adult sample. Over half of the sample reported having no religious affiliation, and only about 34 percent identified as Christian. Appendix table A3A-1 gives the distributions of these political and demographic characteristics for the entire sample, as well as distributions of the opinion variables used in my study and population estimates (where available).

Item nonresponse for the survey was very low. Only five respondents skipped any questions, and these five account for all missingness in the data. The five incomplete responses are excluded only from models that include variables for which there is missing data.

Over half of all respondents favored the ACA. The US adult population reports considerably less favorable attitudes toward the ACA, as the population estimates in Table 3A-1 show. Most respondents knew that the specific provision they were asked about was in the final version of the law, and over half for each provision thought the provision would affect them or someone close to them. Attitudes toward the individual mandate were somewhat mixed, though as predicted more people opposed it than supported it. The dependent coverage provision had very high favorability in this sample, perhaps a result of the generally younger profile of MTurk users, though I do not have the data to support that hypothesis for this sample. The skewed distribution of opinion on the dependent coverage provisions may affect the results of some of my hypothesis tests, which is worth noting here as a potential limitation.

While having two other survey experiments in the study (between my experiment and the demographic questions) could have affected measures like party identification, ideology, and presidential approval, I do not find any evidence that this was the case. The randomization of the treatments was done separately for each experiment. Any effects of one experiment are statistically erased from the other groups by random assignment. There are no significant differences in the distributions of demographic variables across my experimental groups.

### 3.3.2 Planned Analyses

In the results presented below, I set up comparisons based on the specific provisions about which each group was asked. For example, the unprimed group asked about the individual mandate (group 1 in Figure 3-1) is used as a control group, to be compared to the group first primed with questions about the individual mandate (group 2). Similar comparisons are made for the other two groups, with the primed group serving as a treatment group and the unprimed group serving as control.

To test hypothesis 1, I used t-tests of the difference in ACA favorability (a dichotomous variable, 1 = favor, 0 = oppose or neutral) across comparable treatment and control groups. This shows whether, as predicted, any differences in average opinion appear between primed and unprimed groups. I also break the four groups down by favorability toward the provisions asked about, which will prove useful in understanding what the data tells us about hypothesis 1.

Testing of hypothesis 2 employs OLS regression models of ACA favorability estimated separately for the two groups of policy conditions.[^3] Interactions between all variables and whether the respondent was primed are included to test for differences in specific coefficients across groups. Wherever an interaction term is significantly different from zero, we can conclude that the (conditional) correlation between that variable and ACA opinion is different across conditions. Additionally, F-tests of the joint significance of the interaction terms tell us whether being in the primed group significantly changes the overall correlations. These tests will indicate whether the considerations used to form reported ACA opinion are different across primed and unprimed groups (within policy conditions).

## 3.4 Results

If priming different considerations had any effect on opinions, as expected in the first hypothesis, we would expect to see differences in ACA approval levels between the treatment and control groups. Accordingly, I use basic t-tests to determine whether there were significant differences in the mean levels of ACA approval by experimental group. As displayed in Figure 3-2, the two unprimed groups hold similar distributions of opinions on the ACA, and changes occur in the expected directions for the primed groups. That is, support for the ACA is 16 percentage points higher for those primed to think about the popular dependent coverage provision compared to their unprimed counterparts (t = -3.22, p < 0.001), while priming the controversial individual mandate yields somewhat lower favorability, though this latter change is not statistically significant (t = 1.13, p = 0.261).

![Figure 3-2: ACA Favorability by Experimental Group](C:\Users\Robbie\Documents\dissertation\Analysis\Figs\fig3-2.png)

Note: Error bars represent 95% confidence intervals based on unpooled standard errors. The numbers underlying this figure appear in the supplementary online materials, Appendix 3B, Table 3B-1.

The slight decrease in favorability for the group primed with the individual mandate questions shown in Figure 3-2 is commensurate with the more mixed feelings toward the individual mandate expressed in the survey. The dependent coverage provision, by contrast, had much clearer positive effects on the other primed group's perceptions of the ACA. One possible reason for the less significant effect of the individual mandate is the nature of the prime. As @Grande2011 found in their study, feelings on the individual mandate were relatively more positive when using a description of the policy similar to the one I employed.

We might expect that priming the individual mandate will only negatively affect overall ACA opinions of those who oppose the individual mandate. Thus, another way to analyze this data is to break the groups down further into those who favored and did not favor each provision. Figure 3-3 shows this subgroup analysis (I group the middle response category with those opposed, hence the more inclusive label "do not favor"). Among those who do not favor the individual mandate, opinions of the ACA are 16 percentage points less favorable when primed (t = -2.71, p < 0.01). For the group that favored the individual mandate, the prime did not change opinions appreciably (t = -0.374, p = 0.709).

![Figure 3-3: ACA Favorability by Experimental Group and Provision Support](C:\Users\Robbie\Documents\dissertation\Analysis\Figs\fig3-3.png)

Note: Error bars represent 95% confidence intervals based on unpooled standard errors. The numbers underlying this figure appear in the supplementary online materials, Appendix 3B, Table A3B-1.

The same is not true of those in the dependent coverage conditions. No matter how individuals in this group felt about the specific provision, priming the provision increased favorability toward the ACA in general. In fact, those who did not favor the ACA saw increases in favorability of 28 percentage points as a result of the prime (t = 2.61, p < 0.05). This group is somewhat small (only 21 people in the primed portion had less than favorable opinions of this provision), limiting the precision of the estimates for this group. Still, we see evidence here that priming different pieces of the law had different effects on people's opinions. For the individual mandate, the effect depends on how the person feels about the individual mandate. For the dependent coverage provisions, the effect of the prime is not dependent on provision-specific opinions. The discussion section will elaborate further on why this qualitative distinction is important in the context of policy feedbacks.

The main findings in Figures 3-2 and 3-3 hold for various subsets of the sample and various specifications of the test. Using the continuous seven-point scale  as the dependent variable rather than the dichotomous variable yields qualitatively similar results. Effects are similar when the samples are split into those who knew the provisions made it into the final version of the law and those who did not, though it is interesting to note that the effects are stronger for those who did not know the dependent provision was in the law. The individual mandate prime was also stronger for those who did not know the individual mandate was in the ACA, but the prime was not significant for either group.

The results presented above might be biased if the question order affected respondents' opinions of the specific ACA provisions. Imagine an experiment designed to test the hypothesis that priming *general* ACA opinions affects opinions of a *specific* ACA provision, a causal ordering opposite my hypotheses. If we can use my experiment to support both causal stories, then we cannot logically conclude that either is valid because it means the provision-specific questions have been contaminated by order effects. However, in t-tests similar to the ones reported above, but with provision-specific opinions as the dependent variables, asking the overall ACA questions first creates no significant differences in opinions on either provision. For the individual mandate groups, t = -1.34 (p = 0.18), and for the dependent coverage groups, t = -0.67 (p = 0.51). For the dependent coverage groups in particular, this is remarkable given the potential for cognitive dissonance to decrease peoples' willingness to favor any part of a law they just said they opposed on the whole. That is what happened if we only look at the point estimates, but again that effect is not significant. Apparently, people are not as willing to judge the ACA's parts based on the whole as they are to judge the whole based on which parts are salient at the time of response.

We might also expect the null findings just described because of the way the experiment was set up. In the initial instructions, respondents are reminded that a "health reform bill known as the Affordable Care Act (ACA) or Obamacare was signed into law in 2010." The provision questions also referred back to the ACA, regardless of when they appeared in the survey. This means every respondent was "primed" to think about the ACA, with the only difference being that some of the respondents had answered two questions about the ACA before giving their opinions on specific provisions. Empirically, this difference in the level of the ACA prime does not seem to have had any effect, as the t-tests above show. Thus, it is reasonable to assume that the question order manipulation is not affecting opinions of the specific provisions. "Reverse priming" does not seem to be an issue for this study.

As predicted by our first hypothesis, ACA opinions appear to be subject to priming effects. Based on hypothesis 2, we also expect to see differences between treatment and control groups in terms of the predictors of ACA approval. To test this prediction, I estimated OLS regression models for the two policy groups separately, with the final models using level of ACA approval (a seven-point scale ranging from very unfavorable to very favorable) as the dependent variable and opinions of specific provisions, presidential approval, partisanship, and ideology as predictors. I have switched to the continuous variable for this analysis, as opposed to using the dichotmous variable, to take advantage of the greater variance in the continuous variable. As described above, an indicator variable for whether the person was primed or not and interactions between this indicator and all other predictor variables were also included. Other covariates like income, race, religion, and insurance status did not significantly affect the coefficients of interest when included, so I exclude those from the final models reported below.[^4] Because of the way the interaction terms are specified, the two models can actually be presented as four separate models, one for each experimental group, as in Figure 3-4, which plots the logit coefficients and 95% confidence intervals. Tables containing full model information, including the interaction terms, are found in Appendix 3B (tables A3B-2 and A3B-3).

![Figure 3-4: Models of ACA Approval by Treatment Group](C:\Users\Robbie\Documents\dissertation\Analysis\Figs\fig3-4.png)

Note: Coefficient values measured on the x-axes represent the marginal changes ACA favorability (on a seven-point scale) given a 1-unit increase of the specified predictor. The opinion and presidential approval control variables are also continuous seven-point scales. The partisanship and ideology variables are all dummies, with independents and moderates excluded as the baseline categories. No other variables are included in the model. "Other" categories for partisanship and ideolgoy are included in the models, but not shown for brevity. The constants for the models are also not shown. Sample sizes for the models were 124 for primed individual mandate model, 321 for the unprimed individual mandate model, 129 for the primed dependent coverage model, and 325 for the corresponding unprimed model. See Appendix 3A for an explanation of the disparities in group sample sizes. The adjusted R^2^'s for the models range from 0.46 to 0.76. Full models are shown in tabular form in the supplementary online materials, Appendix 3B, tables A3B-2 and A3B-3.

The models show that opinions of specific provisions significantly affect overall opinions of the ACA in all treatment groups. As support for either of the two provisions increases, support for the ACA overall also increases. However, in the individual mandate models, the effect of provision-specific opinions is stronger for the primed group than the unprimed group, with a difference in effect size of about 0.14 (t = 1.80, p = 0.072) on the seven-point scale. What this means is that the prime made the effect of individual mandate opinions on ACA opinions stronger relative to the unprimed group.

The individual mandate results also reveal that priming this provision makes Republican partisanship an insignificant predictor of overall ACA opinion. This change is statistically meaningful, based on the significant interaction terms (t = 3.00, p < 0.01). Given the general strength of partisanship as a predictor of individual political attitudes, including those related to the ACA [@Henderson2011; @Jacobs2016], the fact that partisanship can be rendered an insignificant predictor of ACA opinion is striking. This suggests that opponents of the law may be able to overcome partisan divisions by appealing to design aspects such as the individual mandate. F-tests of joint significance of the interactions also confirm that the predictors of primed and unprimed individual mandate groups are indeed different overall (F = 2.64, p < 0.01).

There is no consistent or significant difference in the primed and unprimed coefficients for the dependent coverage group models (F = 0.93, p = 0.494; no single interaction term is significantly different from zero). This may be a result of the low variance in opinions of the dependent coverage provision. Most respondents (almost 82 percent) liked this provision at least somewhat, and only eight percent had even a slightly unfavorable view of it.

An alternative specification of these models using ordered logit instead of OLS does not qualitatively change these results (see Appendix 3B, tables 3B-4 and 3B-5). As mentioned, the coefficients of interest are also not affected appreciably by the inclusion of other demographic variables. However, logit models with the dichotomous ACA approval variable used in the t-tests above as the dependent variable, the priming effects described in the individual mandate models disappear. This is because most of the changes being picked up by the ordered logit models are occuring in the lower range of the ACA approval scale. Priming the individual mandate affects those who already oppose the ACA, which means the dichotmous variable (favor or oppose) does not change. This presents an important caveat to the analysis of hypothesis 2: prime-driven changes in the predictors of opinion may only occur among those already opposed to the law.

As with hypothesis 1, reverse causality/ opposite causal ordering may threaten our ability to draw causal inferences. It may be the case that ACA opinions are also causing changes in provision-specific opinions, depending on which was asked about first. Models in which the provision opinions are the dependent variables and overall ACA opinions are controlled indicate that ACA opinions do indeed affect provision-specific opinions. However, there are no significant differences in the effects of ACA opinions based on priming. The model coefficients, tested jointly as above, are also not significantly different. The threat of endogeneity is still present, and future work may be needed to get unbiased estimates of the conclusions I make here. Still, there is tentative support for my hypotheses, and reverse causality does not appear to directly explain those results.

## 3.5 Discussion

This study has explored the nature of public opinion on the ACA, specifically investigating how two provisions in the law affect overall opinions. One policy, the dependent coverage provision, was found to be effective pork for supporters, significantly increasing general ACA support relative to the unprimed group. When respondents answered questions about this provision first, their opinions of the ACA were more favorable than those of the unprimed group. While priming the individual mandate, a potential wedge issue, did not affect opinions overall, it did for the subset who opposed the individual mandate. Furthermore, priming this more controversial provision changed the way people formed their opinions of the ACA. The individual mandate prime made respondents' opinions of the provision even more salient and their partisanship less salient in expressing their favorability toward the law as a whole. Both the policy pork provision and the wedge provision worked as predicted.

What does this mean for the ACA's political future? I will not be able to predict precise changes in public opinion, but I can comment on general trends to watch. First, many of the ACA's more popular policy pork provisions are safe. Despite the promises of Republican presidential candidates and others to "repeal every word of Obamacare," to take the wording of Republican Senator and presidential candidate Ted Cruz, portions like the dependent coverage provision are politically untouchable. There are probably also many parts of the law that have remained out of the public eye that will remain similarly safe (see chapter 2 for a discussion of the group-based politics that will predominate in these cases).

However, this policy pork does not appear to have neutralized the potency of potential wedge issues in the ACA, something which supporters hoped to have already acomplished at this point in the law's implementation. Polls on the ACA have shown largley stable levels of support and opposition throughout the past six years. Now that the individual mandate and other significant provisions are being implemented, the pork provisions are much less relevant, having been buried in a deluge of rhetoric about choice and government overreach vs. responsibility and the public good.

As controversial features of the ACA like the individual mandate, Medicaid expansion, the employer mandate, and the Cadillac tax (in 2018) are implemented, their divisiveness will become more apparent, and there is little that can be done to prevent it at this point. My survey experiment shows that interpretive feedback effects are strong for the individual mandate, enough to significantly increase the level of opposition to the ACA overall. Keep in mind that I did not even try to present the mandate to respondents in an unfavorable light. My questions did not mention the mandate's more detestable features, like the fine for noncompliance. Health reform opponents will certainly be less kind in talking about this provision. While I did not directly test how people would behave if primed with both the individual mandate and the dependent coverage provision, the fact that the wedge still works as opponents would intend at this point is not good news for reformers. Parts of the ACA are still very much ground zero for political conflict, and will be for the foreseeable future.

What we will see in the coming years is the political equivalent of trench warfare over the ACA, with both sides fighting fiercely over inches they will probably not hold for long, barring some major external shock such as a wave election. While the broader status quo prevails, the wedges will continue to be driven in, casting the ACA in terms that are certain to divide the public and reinforce the conflict. With no prok left at their disposal to advance positive interpretations of the law, ACA supporters must now hope the law can hold together long enough for more people to benefit and for opponents to give up the fight as they try to hold together what support they do have on their side of the wedge issues. While reformers did make a swift and powerful initial advance in passing the ACA and implementing its easier provisions, the opposition has now had time to firmly entrench itself and hold its position, forcing ACA supporters to do the same. Opponents, however, have no way to effect universal opposition to the ACA (just divisive wedges), so a quick, decisive victory was never a realistic option for them, and will not be for either side in the foreseeable future.

Speaking more generally on the implications of my study for policy feedback theory, the data presented support feedback scholars' assumption that policies can affect the mass public's opinions through the way they interpret the law. This is entirely separate from the resource-based effects that are observed for beenficiaries of a program. More research could be performed on what exactly constitutes effective policy pork. Do these need to be less severable from the more controversial parts of a proposal in order to succeed? How have they been used effectively (or ineffectively) in the past? Can any of these concepts be measured reliably? Such studies would build on my results and advance our understanding of mass feedback effects even further.

## References

[^1]: In fact, the dependent coverage provision probably works against a major purpose of the individual mandate: to bring healthy (often young!) people into the newly redesigned individual insurance market. Keeping young people in the group insurance market (on their parents' plans) by fiat will keep most of them from even considering entering the individual market, especially since the dependent coverage provision was implemented years before the new individual marketplaces, raising the likelihood of adverse selection in those markets at least marginally. Still, the political benefits of including the dependent coverage provision as policy pork were expected to outweigh the policy costs. It would have done no good to have designed an individual market that had the best chance of long-term actuarial success if political opposition had led to the ACA's repeal before implementation.

[^2]: The lower compensation is a result of not having the other two experiments in this wave, resulting in a much shorter questionnaire.

[^3]: While it is generally good practice to use ordered logit model specifications for ordered categorical variables, I deliberately use OLS in this study because the nonlinearities of ordered logit models make the interpretations of the interaction terms less clear. For testing hypothesis 2, it is important to have cleanly interpretable tests of differences in predictors across the primed and unprimed groups. I use ordered logit specifications as a robustness check, reported briefly later in the text and in Appendix 3B, tables A3B-4 and A3B-5, but I rely on the OLS models in my analysis.

[^4]: The coefficients in the final models all change by negligible amounts when the other controls are included, with no changes in significance. Measures of model fit barely change at all. I am confident that the more parsimonious model reported in the text and Figure 3-4 explains as much of the relevant variation as I can with the measures I collected. This, of course, does not preclude unobserved factors from having effects on ACA opinion. However, I am most interested in the changes in coefficients, which are extremely robust across specifications of the model and appear to be driven by random assignment to treatment group, strengthening our ability to draw causal inferences. There are also no significant changes in the models when presidential approval or ideology are omitted. I include these variables because opinions of the ACA are strongly correlated with opinions of President Obama and ideology (as the final models show).

