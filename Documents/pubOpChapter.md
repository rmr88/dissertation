# 3. Interpetive Feedback Effects and Public Opinion on the Affordable Care Act: A Survey Experiment

- Abstract
- be sure switch to "dependent coverage" is consistent across tables, figures, text, etc.
- Check on effects of exposure to other survey experiments on demographic variables (randomization should take care of that for my experimental groups, though)
- Substantive significance of results?
- Why no other covariates in model?
- Why continuous ACA opinion DV?
- Be more specific about alternative specifications in footnotes.
- One reviewer "demands additional exploration" of the disappearance of partisan effects on opinion.
- (?) include most relevant survey questions in text?
- (?) explore uninsured subgroup?

## Introduction

While the Patient Protection and Affordable Care Act (ACA) was passed over six years ago, the political debate over the health reform law has not yet ended. There have been numerous court cases about the law and specific parts thereof, with the court declaring a key piece of the law, the Medicaid expansion requirement, unconstitutional and leaving the decision up to the states. Many states have refused to expand Medicaid, and have also opted to use the Federal insurance exchange rather than setting up their own state exchanges as the law's architects initially envisioned. The House of Representatives has voted dozens of times to repeal the ACA. One recent attempt actually made it through the Senate (on reconciliation, which waives the Senate's supermajority requirements for cloture) and to the President's desk, where it was promptly vetoed. The fact that a repeal bill made it that far for the first time six years after passage and well into implementation is striking, and signals that at least some Republicans really are serious about repealing the ACA and do not feel much pressure from beneficiaries of the law to back down. If Republicans hold Congress and take the White House in the 2016 elections, the last obstacle to those efforts (a Democratic president's veto) will effectively have been removed. All three remaining Republican candidates have vowed to repeal Obamacare. In their analysis of the ACA's shaky political foundation, Oberlander and Weaver conclude "the fight over Obamacare is not over" [@Oberlander2015].

Public opinion on the ACA is still mixed, with small but persistent pluralities in opposition [@DiJulio2015; see also @Jacobs2016]. This matters for the law's future. Public opinion affects health policy through elections and other influences on elected officials [@Jacobs2000; @Jacobs1993; @Skocpol1994; @Skocpol1996], who will ultimately decide the law's fate. For example, the refusal of some states to expand Medicaid and even to close down otherwise successful state health insurance exchanges (as Kentucky is in the process of doing) are a result of continued public opposition and elected officials who represent that opposition in ways that hinder the ACA in achieving its goals. To make predicitons about the political future of health reform in America, we need to understand public opinion and how it might change (or not).

One of the most important factors to examine is the effect of the law itself, as it is both implemented and interpreted, on public attitudes. Was the law written in such a way that it will soon become entrenched and impossible to remove, like Social Security and Medicare, or will it fail to cultivate a large enough support coalition and collapse, be repealed, or be watered down to the point of insignificance? Policy feedback theory, which I will discuss in detail below, provides a few key insights. In this study, I present findings from a survey experiment designed to examine how the ACA's provisions might be interpreted by the public and thereby affect public opinion, filling a gap in the feedback literature on interpretive effects of policy design on mass attitudes. Filling this gap in turn allows me to use policy feedback theory to comment on the strategies and outcomes that can be expected with respect to public opinion on health reform.

Briefly, the results suggest that both opinions of the law and the way those opinions are formed can change depending on what information is in the person's mind at the time. Based on past research and the findings of this study, I argue that the ACA is written in such a way that different elements of the law can invoke different public responses to the law as a whole. Because material benefits of the law will, by design, remain somewhat narrowly focused, I argue that interpretive feedback effects will be more relevant to the health reform debate than material/ resource effects. To the extent this argument holds, there are strong reasons to suspect that opinion on the ACA will remain fundamentally divided, ensuring neither side of the debate will back down any time soon. The application to policy feedbacks also allows my findings to be applied qualitatively to other policies and their effects on public opinion.

## Background

Previous research has advanced our understanding of public opinion on health reform in a few key ways. Partisanship is highly correlated with peoples' opinions of the law [@DiJulio2015]. Polling has also shown that although slim majorities have generally opposed the ACA as a whole, voters overwhelmingly favor some parts of the law [@Brodie2010]. However, there is a sizable portion of voters who do not express any opinion on the ACA [@DiJulio2015], and research shows these people are systematically different from those who do express opinions in terms of demographic and socioeconomic characteristics [@Berinsky2011]. A racial element of opinion on health reform has also arisen, casting the reform in implicitly racial terms [@Henderson2011; @Tesler2012]. These findings suggest some general contours for opinion on health reform, but our knowledge about how the landscape might shift is less certain. Understanding the dynamics of public opinion is important in predicting how the debate will play out.

There have been a few public opinion studies on these dynamics, showing the potential for changes in ACA approval based on certain factors. Support for the ACA or health reform in general is correlated with favorability toward specific provisions in the law [@Grande2011], increased knowledge of the law [@Gross2012], partisanship and self-interest [@Gross2012; @Henderson2011], and beliefs about who deserves government assistance [@Gollust2011]. Using a panel survey design, @Jacobs2016 analyzed within-person trends in ACA opinion over time, as well as the effects of partisanship, perception of direct benefits from health reform, and other factors on those overall opinions. They find that opinion on the law has remained divided, with personal opinions remaining largely entrenched over time, but with significant decreases in support for repealing the ACA. While they conclude that outright repeal of the ACA grows less likely with the passage of time, there is also no evidence that political support for the law will increase any time soon in the manner that reformers initially hoped.

As @Jacobs2011 point out, it is not enough to understand the short-term effects of "situational framing" on ACA opinion. If we want to know what will happen to the law politically in the long term, we need to examine "structural framing." One of the most important sources of structural framing is the design of the ACA itself and the way that design is used to structure public discourse on the law.

Policy feedback theory has already proven to be a useful analytical tool in examining this aspect of the ACA. Much has been written about policy feedbacks and their specific application to health policy and the ACA [for example, @Oberlander2015; @Campbell2011]. In general, the theory predicts that politicians trying to get a major policy passed will attempt, wherever possible, to package the proposal so that concentrated benefits are realized sooner and costs incurred later [@Pierson1993; @Pierson2000; @Campbell2012; @Oberlander2015]. This serves to build a coalition of political support early in a program's existence. There are constraints on would-be reformers' ability to accomplish this, such as budgetary and administrative considerations, political coalitions of elected officials, and existing stakeholder interests [@Oberlander2015; @Patashnik2013].

One of the main assumptions of policy feedback theories relevant to this discussion is that policy design affects opinions [@Campbell2011, 962]. This is expected to occur either through interpretive effects, or the ways in which the public perceives or interprets a policy, or resource-based effects, whereby specific groups receive direct tangible benefits and thereby have a vested interest in preserving the program that confers those benefits [see @Pierson1993]. Interpretive effects can be examined at the level of the general public or program beneficiaries specifically [@Campbell2012]. Interpretive effects are important to consider because the other feedback mechanism through which mass opinion might be influenced, resource effects, can only affect part of the population in the near-term,[^1] whereas interpretive effects are manifest among the public as a whole. Part of the design of the ACA was to expand insurance coverage as much as possible while leaving the rest of the system untouched [@Oberlander2015]. This is one of the key ways in which constraints on design (opposition to disrupting the status quo, in this case) affect policy design. Although some policies may be designed to build resource-based support among large portions of the population and may be successful at doing so, the ACA was not and could not be designed in this manner. Unless the ACA remains intact long enough to deliver *recognizable* benefits to a substantial majority of the population, the balance of overall opinion on health reform will be based mainly on political interpretations. Therefore, this study focuses on the interpretive effects assumed to exist in policy feedback theory.

At a system level, this prediction requires some link between opinion and policy making. In other words, aggregate responsiveness of policy to public opinion and vice versa must occur. The thermostatic model [@Soroka2010] provides one such plausible system-level mechanism. As policy changes, the model predicts, an attentive public will respond by changing its expressed desire for policy change. As budget appropriations for a program increase, fewer people will report wanting more spending on that program and more will report wanting less. Legislators will respond by stopping the increase in spending and perhaps decreasing it. The cycle continues as the public responds to the new changes. @Soroka2010 provide evidence of this prediction in three different countries (US, UK, Canada), concluding that although institutions can affect the strength of this thermostatic relationship, such a relationship does exist. More generally, the macro polity model of @Erikson2002 and its supporting evidence show that aggregate public opinion responds to changes in national conditions and politicians' policy choices. Thus, it is plausible to assume, as policy feedback studies do, that policy and aggregate public opinion can feed back onto each other.

What the thermostatic and macro polity models lack, for purposes of validating this hypothesized link, is an individual-level mechanism and evidence that individuals actually do interpret differently-designed policies differently. Without such a plausible causal link, then the individual-level levers posited by feedback scholars may not be leading to observed aggregate responses. The memory-based model of the survey response [@Zaller1992a] provides a plausible mechanism. According to this model, a person asked to respond to a survey question first retrieves a few relevant pieces of information. This is not an exhaustive (or exhausting) search of one's entire memory, but rather a nonrandom sample of considerations conveniently at the "top of the head." The retrieved considerations are processed and mapped onto possible answers to the question. Thus, reported attitudes may change significantly, depending on what relevant information has been on a respondent's mind recently [@Zaller1992a]. To the extent that policy design elements can serve as considerations in opinion formation, this mechanism is consistent with the predictions of policy feedback theory.

The existence of these mechanisms supports policy feedback predictions of attitude change in important ways. However, there is still one crucial link in the chain left to test: do elements of policy design affect the opinions people form about the policy? The idea that policies will change opinions cannot be taken for granted, nor is this tested specifically by the memory-based model or the macro-level models. The macro models merely show that opinion change follows policy change, which is not sufficient to say that this public response would be altered if policies were designed or interpreted differently. The memory-based model, as mentioned, provides a plausible individual-level mechanism for the required attitude change, but not a guarantee that the mechanism will be used or that overall opinion change will occur. Despite the strength of the policy feedback theory's predictions of attitude change, policy feedback scholars must still design their own tests to verify that the mechanisms described above are actually manipulated by policy.

Quantitative studies in the policy feedback tradition find mixed evidence on this point [@Morgan2011; @Soss2007; @Campbell2012]. The evidence is especially thin with regard to effects on opinion generally, as opposed to opinion among program beneficiaries. To my knowledge, there have been no causal studies of the effect policies, or at least public understanding of policies, have on attitudes. Thus, there is a significant gap in the literature on policy feedbacks surrounding this key prediction of attitude change, limiting the analytical utility of applying policy feedbacks to public opinion on the ACA. Closing this gap would allow us to comment more specifically on the ACA's future with public opinion.

The present study fills this gap using a survey experiment to examine whether priming different aspects of a reform package changes overall opinions. This procedure mirrors survey experiments reported in the survey methodology literature, such as a classic experiment reported by @Schuman1981 in which respondents were much more likely to favor allowing communist reporters into the US when they were first asked whether the Soviet Union should admit American reporters. This and other similarly designed experiments have been shown to change the "weights respondents give to the factors relevant to answering a question" [@Krosnick2010, 293]. Furthermore, asking specific questions about a topic before asking more general questions can affect the context in which answers to the more general questions are generated [@Krosnick2010]. This use of priming thus operates according to the mechanism predicted by the memory-based model. To put it in the context of this study, asking specific questions about ACA provisions may cause some respondents to report opinions about the ACA in general that are more correlated with their answers to the specific questions than they would be in the absence of the prime. These are exactly the kinds of effects we would expect to see given policy feedback theory's predictions, which I will operationalize in the next paragraphs.

Based on policy feedback theory and the prior research summarized above, we can derive two hypotheses to be tested in this study. First, we might expect that if provisions within the ACA are primed before overall opinion of the ACA is reported, then those overall opinions will be different than if those provisions were not salient. Put another way, if respondents are primed to think about a specific provision, their average reported favorability of the ACA would differ from the favorability reported by otherwise similar respondents not primed to think about the provision. We would expect different provisions to move opinion differently, such that priming provisions that tend to be viewed more favorably will move ACA opinion in a positive direction.

Second, given the plausible individual mechanism presented in the memory-based model, we might expect the way in which responses to the ACA favorability question are formed to vary according to what information is salient at the time of response. If a specific provision is salient (because of priming) in a respondent's mind at the time ACA favorability is reported, then the respondent's opinion of the ACA will be more strongly affected by his/ her opinion of the salient provision. Conversely, if no specific provisions are primed, then other factors will be more important in forming the opinion. 

By testing these hypotheses, we can assess whether certain design aspects of the law affect the public's interpretation of and favorability toward the ACA as a whole. Note this is not a test of favorability towards the provisions themselves, nor is it an estimate of the population parameter for ACA favorability. The hypotheses deal with changes in average opinion, not estimates of average opinion itself. Note also that this is not a test of the memory-based model, as the design will be between-person rather than within-person. Data in support of these hypotheses would, however, increase confidence that priming policy provisions (thereby making respondents interpret the law differently) causes aggregate opinion change.

## The Study

To test the hypotheses raised above, I conducted a survey experiment [@Mutz2011] in November 2014 on Amazon's Mechanical Turk (MTurk) service. MTurk respondents have the opportunity to complete a wide range of simple tasks, such as tagging images, coding expense reports, and taking surveys, in return for small financial rewards. Respondents opt in to each task, using MTurk's user interface that presents a list of available tasks and can be filtered or sorted by task metadata such as keywords, date, and payment amount. The exact topic of my survey was concealed until after respondents had opted in. Respondents knew they would take a survey, but not that it would deal specifically with the ACA. Implications of the choice of this subject pool are discussed later.

In the experimental portion of the survey, random assignment was used to sort respondents into one of four experimental conditions, outlined in Figure 1. In two of the experimental groups, respondents were first asked to respond to two questions about their opinion of the ACA in general. These two groups then responded to questions about specific pieces of the law. One group answered questions about the individual mandate (the requirement that most individuals purchase health insurance or pay a fine), while the other was asked about the provision requiring that adults under age 26 be allowed to remain on their parents' insurance plans. I refer to both of these groups as the unprimed or control groups. For the other two groups, which I refer to as the primed or treatment groups, the order of the two question blocks was reversed, so the provision-specific questions came first and the general ACA questions appeared afterward. The question wordings and their order within the blocks remained constant. Only the order of the blocks and the specific provision referred to in the questions was changed.

![Figure 1: Survey Experiment Design](C:\Users\Robbie\Documents\dissertation\Analysis\Figs\fig3-1.png)

By manipulating the order of the questions, respondents in different groups had different considerations "at the tops of their heads" when responding to the general ACA questions. The primed groups had been primed to think about the specific provisions they were asked about immediately prior to giving their opinions of the law as a whole.

In the initial wave of the experiment (Nov. 22 and 24, 2014), 506 responses were collected. Each respondent was paid \$0.40 for completing the survey (repeat responses were not allowed). This wave included my survey experiment and two separate vignette experiments conducted by two other researchers about racial group identity and terrorist recruiting messages. More information about the other two studies is available from the author upon request. My study appeared first, followed by the other two, with demographic questions at the end. After completing the experimental portion of the survey, respondents reported their level of approval of President Obama, their partisanship and political ideology, their racial identities and religious affiliation, their level of attentiveness to news and current events, their insurance status, and their income level. Specific question wording for my experimental questions and for demographic questions is given in Appendix C.

Upon preliminary examination of the data from the initial wave, it was discovered that the code for my portion of the survey had failed to randomize the order of the general ACA and specific policy questions. This meant I only had data for the two unprimed groups, my "control" groups. In order to collect data for the other two groups, I was able to put my survey experiment (along with the same demographic questions, but excluding the other two experiments) back into the field on MTurk on Nov. 25, 2014, with a compensation rate of \$0.12 per respondent.[^2] Those who had taken the survey previously were barred from participating again. This second wave yielded 396 additional responses. I randomized the treatment group assignments for this second wave in such a way that all four groups were represented, but with twice as many respondents assigned to the two groups that had been omitted in the first wave (the primed groups).

Collecting data on all four groups in the second wave allowed me to assess whether respondents to the two waves were different based on observed characteristics. I checked to ensure that there were no significant differences in the types of respondents to the two waves. Each wave had a different estimated completion time and a different level of compensation, in addition to being fielded on different days. However, there is no indication that responses were affected by these differences. Balance checks revealed that on all 16 items relevant to my survey (including both demographic and ACA-related items), only ideology differs significantly across waves, and that difference only appears for one specification of the variable. Specific results of these balance checks are reported in the tables in Appendix A, along with final sample sizes within each treatment group. The analyses in the main body of this paper combine data from both waves of the survey, with treatment presumed to be given at random. Results do not change significantly when respondents from the first wave are omitted.

### Sample Demographics and Descriptive Statistics

The use of MTurk as a survey platform has some limitations. As an opt-in survey conducted over the Internet, there is no way to randomly select respondents, nor is there any way to calculate response rates, refusal rates, margins of sampling error, or any of the usual survey metrics. The respondents to my survey do not resemble the demographic or political profiles of the US population, as can be expected from a subject pool such as MTurk. However, experimental results using MTurk have proven comparable to those obtained from other convenient subject pools often used in experiments [see @Mullinix2015]. Thus, for an experimental design, MTurk is an acceptable platform. For the hypotheses I am trying to test, internal validity is more important than external validity. I will report below how the respondents to my survey are different from the population, but I see no reason to expect that my results will differ qualitatively if applied to the general population. As it is not my intent to estimate population parameters, but rather to gauge the effectiveness of an experimental manipulation, data collected on MTurk is suitable for this study.

I asked respondents for their level of approval/ disapproval of President Obama, party identification (using the standard ANES question), ideology (liberal to conservative, 7-point scale with ANES wording but no branching), racial and religious identification, level of attentiveness to news, health insurance status, and income. As mentioned above, MTurk does not provide a good platform for representative survey results, and my sample is skewed on all observable characteristics in the ways we would expect of MTurk respondents. They are more liberal and Democratic, more likely to be uninsured, and have lower incomes than we would expect from a general US adult sample. Over half of the sample reported having no religious affiliation, and only about 34 percent identified as Christian. Table 1 gives the distributions of these political and demographic characteristics for the entire sample, as well as distributions of the opinion variables used in my study and population estimates (where available).

Table 1: Descriptive Statistics

**\[Table 1 about here\]**

The table indicates very little missing data. Only five respondents skipped any questions, and these five account for all missingness in the data. The five incomplete responses are excluded only from models that include variables for which there is missing data.

Based on Table 1, we see that over half of all respondents favored the ACA. The US adult population reports considerably less favorable attitudes toward the ACA, as the population estimates in Table 1 show. We also see that most people knew that the specific provision they were asked about was in the final version of the law, and over half for each provision thought the provision would affect them or someone close to them. Attitudes toward the individual mandate were somewhat mixed, though as predicted more people opposed it than supported it. The dependent coverage provision had very high favorability in this sample, perhaps a result of the generally younger profile of MTurk users, though I do not have the data to support that hypothesis for this sample. The skewed distribution of opinion on the dependent coverage provisions may affect the results of some of my hypothesis tests, which is worth noting here as a potential limitation.

### Planned Analyses

In the results presented below, I set up comparisons based on the specific provisions about which each group was asked. For example, the unprimed group asked about the individual mandate (group 1 in Figure 1) is used as a control group, to be compared to the group first primed with questions about the individual mandate (group 2). Similar comparisons are made for the other two groups, with the primed group serving as a treatment group and the unprimed group serving as control.

To test hypothesis 1, I used t-tests of the difference in ACA favorability across comparable treatment and control groups. This shows whether, as predicted, any differences in average opinion appear between primed and unprimed groups. I also break the four groups down into various subgroups to analyze differential treatment effects for these groups. In particular, breaking experimental groups down by favorability toward the provisions asked about will prove useful in understanding what the data tells us about hypothesis 1.

Testing of hypothesis 2 employs OLS regression models of ACA favorability estimated separately for the two groups of policy conditions. Interactions between all variables and whether the respondent was primed are included to test for differences in specific coefficients across groups. Wherever an interaction term is significantly different from zero, we can conclude that the (conditional) correlation between that variable and ACA opinion is different across conditions. Additionally, F-tests of the joint significance of the interaction terms tell us whether being in the primed group significantly changes the overall correlations. These tests will indicate whether the considerations used to form reported ACA opinion are different across primed and unprimed groups (within policy conditions).

## Results

If priming different considerations had any effect on opinions, as expected in the first hypothesis, we would expect to see differences in ACA approval levels between the treatment and control groups. Accordingly, I use basic t-tests to determine whether there were significant differences in the mean levels of ACA approval by experimental group. As displayed in Figure 2, the two unprimed groups hold similar distributions of opinions on the ACA, and changes occur in the expected directions for the primed groups. That is, opinion is significantly higher for those primed to think about the popular dependent coverage provision compared to their unprimed counterparts (t = -3.62, p < 0.001), while priming the controversial individual mandate yields somewhat lower opinions (t = 1.79, p =0.074). For the dependent coverage group, the substantive effect of the prime is an increase in favorability by almost three quarters of a scale point on the seven-point favorability scale.[^3]

![Figure 2: ACA Favorability by Experimental Group](C:\Users\Robbie\Documents\dissertation\Analysis\Figs\fig3-2.png)

Note: Error bars represent 95% confidence intervals based on unpooled standard errors. The y-axis variable ranges from 1-7, and is treated as continuous in this analysis. Results do not change significantly when the dependent variable is changed to a dummy representing presence of any favorable feeling toward ACA. The numbers underlying this figure appear in the supplementary online materials, Appendix B, Table B-1.

The decrease in favorability for the group primed with the individual mandate questions shown in Figure 2 is commensurate with the more mixed feelings toward the individual mandate expressed in the survey. The dependent coverage provision, by contrast, had much clearer positive effects on the other primed group's perceptions of the ACA. One possible reason for the less significant effect of the individual mandate is the nature of the prime. As @Grande2011 found in their study, feelings on the individual mandate were relatively more positive when using a description of the policy similar to the one I employed.

We might expect that priming the individual mandate will only negatively affect overall ACA opinions of those who oppose the individual mandate. Thus, another way to analyze this data is to break the groups down further into those who favored and did not favor each provision. Figure 3 shows this subgroup analysis (I group the middle response category with those opposed, hence the more inclusive label "do not favor"). Among those who do not favor the individual mandate, opinions of the ACA are significantly less favorable when primed (t = -3.47, p < 0.001). For the group that favored the individual mandate, the prime did not change opinions (t = -0.812, p = 0.418).

![Figure 3: ACA Favorability by Experimental Group and Provision Support](C:\Users\Robbie\Documents\dissertation\Analysis\Figs\fig3-3.png)

Note: Error bars represent 95% confidence intervals based on unpooled standard errors. The y-axis variable ranges from 1-7, and is treated as continuous in this analysis. Results do not change significantly when the dependent variable is changed to a dummy representing presence of any favorable feeling toward ACA. The numbers underlying this figure appear in the supplementary online materials, Appendix B, Table B-1.

The same is not true of those in the dependent coverage conditions. No matter how individuals in this group felt about the specific provision, priming the provision increased favorability toward the ACA in general. The "do not favor" segment of this group is somewhat small (only 21 people in the primed portion had less than favorable opinions of this provision), limiting the precision of the estimates for this group. Still, we see evidence here that priming different pieces of the law had different effects on people's opinions. For the individual mandate, the effect depends on how the person feels about the individual mandate. For the dependent coverage provisions, the effect of the prime is not dependent on provision-specific opinions. The discussion section will elaborate further on why this qualitative distinction is important in the context of policy feedbacks.

The main findings in Figures 2 and 3 hold for various subsets of the sample and various specifications of the test. Using a dummy variable as the dependent variable rather than the continuous seven-point scale yields qualitatively similar results (the individual mandate prime still has a non-significant negative effect). Effects are similar when the samples are split into those who knew the provisions made it into the final version of the law and those who did not, though it is interesting to note that the effects are stronger for those who did not know the dependent provision was in the law. The individual mandate prime was also stronger for those who did not know the individual mandate was in the ACA, but the prime was not significant for either group.

The results presented above might be biased if the question order affected respondents' opinions of the specific ACA provisions. Imagine an experiment designed to test the hypothesis that priming *general* ACA opinions affects opinions of a *specific* ACA provision, a causal ordering opposite my hypotheses. If we can use my experiment to support both causal stories, then we cannot logically conclude that either is valid because it means the provision-specific questions have been contaminated by order effects. However, in t-tests similar to the ones reported above, but with provision-specific opinions as the dependent variables, asking the overall ACA questions first creates no significant differences in opinions on either provision. For the individual mandate groups, t = 0.052 (p = 0.96), and for the dependent coverage groups, t = -1.19 (p = 0.23). For the dependent coverage groups in particular, this is remarkable given the potential for cognitive dissonance to decrease peoples' willingness to favor any part of a law they just said they opposed on the whole. That is what happened if we only look at the point estimates, but again that effect is not significant. Apparently, people are not as willing to judge the ACA's parts based on the whole as they are to judge the whole based on which parts are salient at the time of response.

We might also expect the null findings just described because of the way the experiment was set up. In the initial instructions, respondents are reminded that a "health reform bill known as the Affordable Care Act (ACA) or Obamacare was signed into law in 2010." The provision questions also referred back to the ACA, regardless of when they appeared in the survey. This means every respondent was "primed" to think about the ACA, with the only difference being that some of the respondents had answered two questions about the ACA before giving their opinions on specific provisions. Empirically, this difference in the level of the ACA prime does not seem to have had any effect, as the t-tests above show. Thus, it is reasonable to assume that the question order manipulation is not affecting opinions of the specific provisions. "Reverse priming" does not seem to be an issue for this study.

As predicted by our first hypothesis, ACA opinions appear to be subject to priming effects. Based on hypothesis 2, we also expect to see differences between treatment and control groups in terms of the predictors of ACA approval. To test this prediction, I estimated OLS regression models for the two policy groups separately, with the final models using level of ACA approval as the dependent variable and opinions of specific provisions, presidential approval, and partisanship as predictors. An indicator variable for whether the person was primed or not and interactions between this indicator and all other predictor variables were also included, as described above. Other covariates like ideology, income, race, religion, and insurance status did not significantly affect the coefficients of interest when included, so I exclude those from the final models reported below. Because of the way the interaction terms are specified, the two models can actually be presented as four separate models, one for each experimental group, as in Figure 4, which plots the coefficients and 95% confidence intervals. Tables containing full model information, including the interaction terms, are found in Appendix B.

![Figure 4: Models of ACA Approval by Treatment Group](C:\Users\Robbie\Documents\dissertation\Analysis\Figs\fig3-4.png)

Note: Coefficient values measured on the x-axes represent the effects of each variable on overall ACA opinion (seven-point scale). The opinion and presidential approval control variables are also continuous seven-point scales. The partisanship variables are all dummies, with independents excluded as the baseline categories. No other variables are included in the model. The constants for the models are not shown. Sample sizes for the models were 124 for primed individual mandate model, 321 for the unprimed individual mandate model, 129 for the primed dependent coverage model, and 326 for the corresponding unprimed model. See Appendix A for an explanation of the disparities in group sample sizes. The adjusted R^2^'s for the models range from 0.46 to 0.76. Full models are shown in tabular form in the supplementary online materials, Appendix B, tables B-2 and B-3.

The models show that opinions of specific provisions significantly affect overall opinions of the ACA in all treatment groups. As support for either of the two provisions increases, support for the ACA overall also increases. However, in the individual mandate models, the effect of provision-specific opinions is somewhat stronger for the primed group than the unprimed group, with a difference of about 0.13 on the seven-point scale. What this means is that the prime seems to have made the effect of individual mandate opinions on ACA opinions stronger relative to the unprimed group. This finding of a difference in the two coefficients is not quite statistically significant (t = 1.73, p = 0.085), but a significant finding of this type would be consistent with my predictions. The 0.13 increase in effect size is extremely robust across different specifications of the model, leading me to suspect the null finding is more of a power issue than an actual lack of a priming effect.[^4]

Strikingly, the individual mandate results also reveal that priming this provision makes partisanship an insignificant predictor of overall ACA opinion. Given the general strength of partisanship as a predictor of individual political attitudes, including those related to the ACA [@Henderson2011; @Jacobs2016], the fact that partisanship can be rendered an insignificant predictor of ACA opinion is striking. This suggests that opponents of the law may be able to overcome partisan divisions by appealing to design aspects such as the individual mandate. F-tests of joint significance of the interactions also confirm that the predictors of primed and unprimed individual mandate groups are indeed different overall (F = 4.72, p = 0.001).

There is no consistent or significant difference in the primed and unprimed coefficients for the dependent coverage group models (F = 0.72, p = 0.58; no single interaction term is significantly different from zero). This may be a result of the low variance in opinions of the dependent coverage provision. Most respondents (almost 82 percent) liked this provision at least somewhat, and only eight percent had even a slightly unfavorable view of it.

As with hypothesis 1, reverse causality/ opposite causal ordering may threaten our ability to draw causal inferences. It may be the case that ACA opinions are also causing changes in provision-specific opinions, depending on which was asked about first. Models in which the provision opinions are the dependent variables and overall ACA opinions are controlled indicate that ACA opinions do indeed affect provision-specific opinions. However, there are no significant differences in the effects of ACA opinions based on priming. The model coefficients, tested jointly as above, are also not significantly different. The threat of endogeneity is still present, and future work may be needed to get unbiased estimates of the conclusions I make here. Still, there is tentative support for my hypotheses, and reverse causality does not appear to directly explain those results.

## Discussion

- I will not be able to predict exactly what public opinion will be in the future, for two important reasons. First, I am using a survey experiment that does not employ a representative sample of the population. Second, I am not directly examining actual political discourse or actual information and interpretations being used widely to talk about health reform. However, I will be able to comment on specific factors will affect the ACA's popularity with the public, particulary with respect to the design of the law itself. (*do I need to include this?*)

This study has explored the nature of public opinion on the ACA, specifically investigating how two provisions in the law affect overall opinions. One policy, the dependent coverage provision, was found to be a powerful prime. When respondents answered questions about this provision first, their opinions of the ACA were more favorable than those of the unprimed group. While priming the individual mandate did not affect opinions overall (though it did for the subset who opposed the individual mandate), priming this more controversial provision did seem to change the way people formed their opinions of the ACA. The individual mandate prime made respondents' opinions of the provision even more salient and their partisanship less salient in expressing their favorability toward the law as a whole.

What the results presented above do is paint a picture of two qualitatively different types of design features with different interpretive effects. I will refer to the first type as "slam dunk" features. The dependent coverage provision, for example, is almost universally favored [based on studies like @Brodie2010]. It is a design feature with an important political purpose: build early support for the new program. ACA supporters could go on offense with slam dunks like these, promising even more good things to come if people will just stick with this newfangled health law (while downplaying the costs that must also come eventually). Design features like the dependent coverage provision, if sold under the right conditions, can accomplish this very effectively. Policymakers apparently remembered the lessons of Medicare Catastrophic and the Clinton health reform plan, which never got the necessary political support despite (or perhaps because of) careful attempts to design the best programs [see @Starr2011]. Even the best policies need some slam dunks built in. The ACA has a few of them, and supporters can use them to drive favorable interpetations of the law among the general public, many of whom will not directly benefit from these specific provisions.

As mentioned, slam dunks must be executed effectively. These provisions may be entirely severable from the rest of the program, meaning that they have to be tied rhetorically to the other provisions of the law. It is not obvious that allowing dependents to remain on their parents' insurance until age 26 goes along with a requirement for most individuals to buy health insurance.[^5] The severability of the slam dunk provision from the rest of the law means that although it will probably stand on its own, it may not be potent enough to shield other parts of the ACA from attacks in the face of sustained opposition. If the slam dunk does not break down opposition to a new program quickly, before the more controversial parts are implemented, then it may not be of much political use in those later stages.

The other type of design feature we have seen is what I will call a potential wedge issue. I say "potential" because some outside effort is required to make these provisions politically potent. If those in favor of the policy control the discussion, the wedges will never be hammered down politically (though they might be felt in other ways). The individual mandate is an example of a potential wedge issue. It does not enjoy inherent universal support, but is rather highly controversial in its own right and serves to enhance public divisions on the whole reform package. Politicians mindful of feedback effects try to include as few wedge issues as possible in a new law in order to increase its chances of political success. However, depending on the constraints imposed on would be reformers, some wedge issues are unavoidable. The decision to try to leave as much of the current status quo intact as possible meant that the ACA almost certainly had to have an individual mandate. From the reformers' point of view, the political strategy was to build initial support using some slam dunks so that as the potential wedge issues were implemented, their divisive effects would be muted. Opponents, given that they were unable to stop the policy from passing at all, hoped to use these wedge issues to prevent such a support coalition from fully forming. However, if their base of support crumbles early as a result of some effective slam dunks from the other side, the wedge loses its potency.

In thinking about how the ACA's design might affect its future public support, the results of this study suggest that how favorably people feel toward the law will depend on what policies are used to interpet the law. If the ACA is framed in terms of expanding coverage to groups such as young adults (who tend to be poorer and uninsured), the poor, and those with pre-existing conditions, it is likely to be viewed favorably. These slam dunks can be used by proponents to build supportive interpretations of the law among the broader public, many of whom will not benefit directly from the slam dunk provisions.

However, the slam dunks appear to have not given reformers any lasting political support. Opponents seem to have successfully innoculated ACA opponents to the slam dunks, shoring up public opposition, but without making any significant advances of their own. Polls on the ACA have shown largley stable levels of support and opposition throughout the past six years. Now that implementation of the law has proceeded to implementation of the individual mandate and other significant provisions, the flashy slam dunks are much less relevant, having been buried in a deluge of rhetoric about choice and government overreach vs. responsibility and the public good. 

With no powerful tools to create positive interpretations of the entire law left at their disposal, ACA supporters are left to hope the law can hold together long enough for more people to benefit and for opponents to give up. Opponents, on the other hand, can still use design aspects of the law to rally support for their side. However, they do not have a countervailing "slam dunk" that will bring about universal opposition to the ACA. What they have are wedge issues that serve only to divide opinion further by making those who oppose the individual mandate even more intensely opposed to the ACA overall. We have also seen that interpreting the ACA based on the individual mandate (and perhaps similarly controversial provisions, such as the employer mandate or the "Cadillac Tax" on expensive employer-sponsored insurance plans) causes opinions to be based more on opinions of the provision rather than on partisanship or other "usual suspects." This brings up the possibility that the wedge will work even across party lines. Democrats in the primied individual mandate group of my study were no more likely than Republicans to oppose the law; it simply became a matter of how they felt about the individual mandate. Again, this is not a slam dunk. Framing the ACA in terms of mandates did not make people oppose the law universally. But it did move opinion nonetheless.

What this discussion implies is that both sides of the American health reform debate can count on settling in for political "trench warfare" over the issue. Supporters have advanced as far as they could before meeting enough resistance to stop their momentum. They got a bill passed, quite an accomplishment in its own right. However, ACA opponents do not have the ability to make a similarly powerful countercharge (i.e. successful passage of a repeal bill). Some provisions of the ACA are likely safe. The popular slam dunk provisions will maintain their public support base. Other parts of the ACA that have not garnered any public attention at all, thus avoiding being swept up in the public rhetoric, are probably also safe unless they arouse public awareness somehow. Therefore, Republicans will probably not be able to repeal literally "every word of Obamacare" (to take the wording of Republican Senator Ted Cruz of Texas). However, important parts of the ACA like the individual mandate, Medicaid expansion, the employer mandate, and the Cadillac tax are still very much ground zero for political conflict, and will be for the foreseeable future.

## References

[^1]: @Jacobs2016 provides good insights into the effects tangible benefits have had on the opinions of those who have received them.

[^2]: The lower compensation is a result of not having the other two experiments in this wave, resulting in a much shorter questionnaire.

[^3]: I treat the seven-point scale of ACA favorability as a continuous variable in this analysis, but results do not change significantly when I specify the dependent variable as a dummy indicating any favorable feelings toward the ACA (with neutral and any unfavorable in the 0 category)

[^4]: Indeed, a rough power analysis indicates I would need to double the number of observations (from 445 to about 897) in the joint model being tested to detect this effect with even a 0.7 power coefficient.

[^5]: In fact, the dependent coverage provision probably works against a major purpose of the individual mandate: to bring healthy (often young!) people into the newly redesigned individual insurance market. Keeping young people in the group insurance market (on their parents' plans) by fiat will keep most of them from even considering entering the individual market, especially since the dependent coverage provision was implemented years before the new individual marketplaces, raising the likelihood of adverse selection in those markets at least marginally. Still, the political benefits of including the dependent coverage provision as a slam dunk were expected to outweigh the policy costs. It would have done no good to have designed an individual market that had the best chance of long-term actuarial success if political opposition had led to the ACA's repeal before implementation.